\documentclass{article}
% Left align stuff
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[document]{ragged2e}
% other stuff
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\PassOptionsToPackage{hyphens}{url}\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}
% \lstset{
% basicstyle=\small\ttfamily,
% columns=flexible,
% breaklines=true
% }
\restylefloat{table}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{10} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{10}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% https://tex.stackexchange.com/questions/83882/how-to-highlight-python-syntax-in-latex-listings-lstinputlistings-command
% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
otherkeywords={self},             % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=tb,                         % Any extra options here
showstringspaces=false
columns=flexible,
breaklines=true
}}


% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

\begin{document}

\title{Command and Control Subsystems Report}
\author{Jake Vossen: OREPACKAGERS}

\maketitle

% \begin{abstract}
% The abstract text goes here.
% \end{abstract}

\section{Subsystem Description}
The Command and Control subsystem is the subsystem responsible for
converting the requests that have been collected into downloaded data
to be distributed to users. It starts by receiving a list of
\texttt{request} objects - a structure for containing information about
each request. To prevent confusion, the mono-spaced \texttt{request}
will refer to they Python object itself, whereas plain ``request''
refers to the concept of a user request.

With this list of requests, the first thing it does is use Pythons
\texttt{multiprocessing}[1] library to split work up between the
different threads on the computer. While this software is designed
for low end machines to be more accessible to developing areas, most
computers[2] in recent times will have more than 1 CPU core (including
the Raspberry Pi[3]). This allows for the processor to split up all
the requests, and execute them in parallel, instead of waiting for each
one to finish individually, which can provide a large performance
boost.

When downloading a \texttt{request}, it determines the type of
request. The types are URL, search, YouTube, and ipfs. It follows this
flow chart to decide what to do:

\begin{figure}[h]
  \centering
  \includegraphics[scale=.6]{log-flow-chart.png}
  \caption{\begingroup \fontsize{10pt}{12pt}\selectfont Diagram describing flow chart of downloading each
    \texttt{request}. Jake Vossen, 2019-04-01 \endgroup}
\end{figure}

The steps for each type of request is outlined below.

\subsection{URLs}

URLs are your basic websites, such as
\url{https://en.wikipedia.org/wiki/Monty_Python_and_the_Holy_Grail},
or
\url{https://www.nytimes.com/2019/03/27/technology/turing-award-ai.html}. This
is for users who already know the content they want. In the backend,
the Python program is going to use the \texttt{wget}[4]
utility. Specifically, \texttt{wget -E -H -k -K -p -P path url
  robots=off} where \texttt{path} is the output directory and
\texttt{url} is the url that has been requested. To break it down:
\begin{itemize}
  \item \texttt{-E} tells \texttt{wget} to change the file extension
    if the url isn't a .html file. This allows for the downloading of
    PDF files as well as HTML files
  \item \texttt{-H} Tells \texttt{wget} that it is okay to download
    material from hosts that aren't from the specified URL. While this
    seems backwards at first, many websites host their fonts or
    pictures in a place that isn't the same as the document that is
    being request. This allows the page to appear just as it would
    when visited in a web browser
  \item \texttt{-k} This stands for ``convert links'', which means
    that when the download is complete, it converts the links on the
    page so they are suitable for browsing on the local machine. For
    example, if a blog has \texttt{otherwebsite.com/picture} on it, it
    will replace that with just \texttt{picture} to ensure that the
    browser will use the local versions of that picture
  \item \texttt{-K} This means that \texttt{wget} will make a backup
    of the HTML file when converting links with the \texttt{-k}
    option.
  \item \texttt{-p} is the most important option, as it tells
    \texttt{wget} to download all the requirements as well as the
    url. So if the site links to an outside source (such as
    \texttt{otherwebsite.com/picture}) also gets downloaded if it is
    linked in the requested url.
  \end{itemize}
All of those options ensures that downloading the URL requested gets
the website exactly as it appears in a browser, including linked
images. Additionally, it works with PDF and ZIP files, which is really
important to ensure all possible media can be obtained. This method is
also used by other parts of the program.

\subsection{Search}

Sometimes the user will not know exactly what they want, so we added
an option to get the first page of Google results (top 10
results). The \texttt{googlesearch}[5] library was very helpful for
this. This library provides a list of URLs, and then we use the URL
method to download those results (or the YouTube download option if it
is a YouTube link). The results are each in their own folder named
based on the google search rank (1 is first result, 2 is second
result, etc). 

\subsection{YouTube}

It is well known that lot of quality educational and entertainment
content is in video format, and the majority of that content is on
YouTube. That is why we are adding functionality to request YouTube
videos (through a link, or a result from the search function). In this
case, the \texttt{youtube-dl} program allows for content retrieval.

\subsection{IPFS}
IPFS stands for ``InterPlanetary File System'', which is a ``A
peer-to-peer hypermedia protocol to make the web faster, safer, and
more open''[7]. The internet that is familiar to most people is the
client-server model[8], but IPFS changes that so everyone is both a
client and a server. Media is distributed based of their crytographic
hash, a unique ID for each object instead of a URL. Anybody can add
objects, and when requesting an object, it can be downloaded from any
number of servers, not just the original person hosting the
server. The \texttt{ipfs} command line utility[9] is used to retrieve
objects.

\section{Interfaces with Other Subsystems}

Software is all about abstraction, so there are a handful of points in
which the Command and Control subsystem will interface with the other
subsystems. Ideally, all the other subsystems will work independently
and a couple of links will get everything working together.

\subsection{Input - List of Requests}

Python only stores objects in memory while the program is
running. That means when the program is shut down (or the machine is
powered off), the data generated must be saved somewhere on the
device or else that information would be lost. In this case, what is
important is to be able to store the \texttt{request} objects. This is
completed by the data management subsystem. This means my subsystem
will call \texttt{get\_all\_requests()} which will retrieve the data
about the requests, create the objects again (as they where destroyed
from memory when the program shut down), and return that information
to Command and Control.

\subsection{Output - Download path and status}

Once my subsystem completes it's download, it needs to update the
database about the new status. This is again through the Data
Management subsystem. To ensure we only download each object once, each
\texttt{request} has two properties: \texttt{file\_location} and
\texttt{downloaded\_status}. Once Command and Control has completed a
download, it will call the Data Management method
\texttt{update\_request(r)} where \texttt{r} include the changes to
\texttt{file\_location} and \texttt{downloaded\_status}. So the
Data Management subsystem knows which database entry to update, we use
a Universally Unique Identifier (UUID)[10] to identify each
request.

\begin{figure}[h]
  \centering
  \includegraphics[scale=.5]{input-output.png}
  \caption{\begingroup \fontsize{10pt}{12pt}\selectfont Diagram
    describing the inputs and outputs of the Command and Control sub-system
    \texttt{request}. Jake Vossen, 2019-04-01 \endgroup}
\end{figure}

\section{Stakeholder Considerations}

The primary concern for the Command and Control subsystem is ensuring
that the primary forms of retrieval are supported. In an interview with
Anthony Wanjiru, who lived in Kenya for 35 years, he said the most
important types of content are either a URL (either as a web page,
pdf, etc), YouTube, Google Searches, and while IPFS isn't widely used,
it has a lot of potential[13]. He also said that local content is on
the rise, and a method to upload content would be really
beneficial. While this was not implemented at this time, due to
specifics with integration with the other subsystems, we hope to
implement this in the final project.

\section{Validation}

Testing is one of the most fundamentally important things in software
development. It is easy to write code, but it is not useful if it
can't work under a variety of difficult tests. A handful of curated
tested designed to test the boundaries of the code have been
picked. To verify the results, there are two primary methods. The
first, is a SHA-512 sum, which is a crytographically secure way to
ensure two files are the same[11]. The first file originally from a
manual download, and the second one from the Command and Control
Subsystem. If the two hashes are the same, the subsystem was
successful. However, this cannot be used for all
tests, because when downloading from a website, the original HTML files
are modified for browsing offline (see the \texttt{-k} option on
wget. This makes it impossible to cryptographically ensure that the
requested file is the same as the downloaded file, so a visual
analysis is preformed to analyze the two documents and ensure that
they are identical. The table below explains the tests preformed,
where the ``Analysis Method'' is either visual or hash to preform the
check. 

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[H]
\centering
\caption{\begingroup \fontsize{10pt}{12pt}\selectfont Tests Preformed
Jake Vossen, 2019-04-01 \endgroup}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|l|l|l|l}
Type   & Value                                                                                     & Expected Result                                       & Analysis Method & Expected = Actual? \\ \hline
URL    & https://www.gutenberg.org/cache/epub/2265/pg2265.txt                                      & Text of ``Hamlet" By Shakespeare                       & Hash            & Yes                \\ \hline
URL    & https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46507.pdf & PDF of Google Machine Learning Research Paper         & Hash            & Yes                \\ \hline
URL    & https://en.wikipedia.org/wiki/Monty\_Python\_and\_the\_Holy\_Grail                        & Wikipedia entry for ``Monty Python and the Holy Grail" & Visual          & Yes                \\ \hline
YouTube & https://www.youtube.com/watch?v=dQw4w9WgXcQ
                                                                                                   & Rick Roll                                 & Visual          & Yes                \\ \hline
search & What Is the Airspeed Velocity of an Unladen Swallow?                                      & Google search results                                 & Visual          & Yes                \\ \hline
ipfs   & /ipfs/QmS4ustL54uo8FzR9455qaxZwuMiUhyvMcX9Ba8nUH4uVv/readme                               & IPFS introduction document                            & Hash            & Yes                \\ \hline
ipfs   & /ipfs/QmVLTMHtLRhnft3QspDx4qTJeXY6hiib1j77UfQmY54CGe/mosaic.png                           & 300 MB picture of the moon                            & Hash            & Yes               
\end{tabular}%
}
\end{table}

The other important validation is to ensure that the multi threading
described in section 1 improves results. I ran the program with 8
fairly large requests and used the \texttt{time}[12] utility to measure
the run time of the program. The results are shown below:

\begin{table}[H]
\centering
\caption{\begingroup \fontsize{10pt}{12pt}\selectfont Tests Preformed
Jake Vossen, 2019-04-01 \endgroup}
\label{my-label}
% \resizebox{\textwidth}{!}{%\begin{table}[]
\begin{tabular}{l|l|l|l}
                                      1 Core  & 2 Cores & 4 Cores & 8
                                                                    Cores
  \\ \hline
 161.277 & 53.927  & 45.984  & 46.448 
\end{tabular}
% }
\end{table}

\section{Appendix}

\pythonexternal{../CommandAndControl.py}

\newpage
\section{Bibliography}

[1] ``multiprocessing - Process-based parallelism,''
\textit{multiprocessing - Process-based parallelism - Python 3.7.3
  documentation}. [Online]. Available:
\url{https://docs.python.org/3.7/library/multiprocessing.html}. [Accessed:
03-Apr-2019].

[2] ``Hardware Survey - CPU Cores,'' \textit{Hardware Survey - CPU Cores}. [Online]. Available: \url{https://www.pcbenchmarks.net/number-of-cpu-cores.html}. [Accessed: 03-Apr-2019]. 

[3] ``Raspberry Pi 3 Model B,'' Raspberry Pi. [Online]. Available:
\url{https://www.raspberrypi.org/products/raspberry-pi-3-model-b/}. [Accessed:
03-Apr-2019].

[4] ``GNU Wget 1.20 Manual,'' \textit{GNU Wget 1.20
  Manual}. [Online]. Available:
\url{https://www.gnu.org/software/wget/manual/wget.html}. [Accessed:
03-Apr-2019].

[5] MarioVilas, ``MarioVilas/googlesearch,'' GitHub,
06-Mar-2019. [Online]. Available:
\url{https://github.com/MarioVilas/googlesearch}. [Accessed:
03-Apr-2019].

[6] Ytdl-Org, ``ytdl-org/youtube-dl'' GitHub,
03-Apr-2019. [Online]. Available:
\url{https://github.com/ytdl-org/youtube-dl/}. [Accessed:
03-Apr-2019].

[7] ``IPFS is the Distributed Web'' IPFS. [Online]. Available:
\url{https://ipfs.io/}. [Accessed: 03-Apr-2019].

[8] ``Client-Server Mode,'' [Online]. Available:
\url{https://web.cs.wpi.edu/~cs513/s07/week1-unixsock.pdf}. [Accessed:
02-Apr-2019].

[9] ``IPFS Documentation,'' \textit{Install IPFS â€“ IPFS Documentation}. [Online]. Available: \url{https://docs.ipfs.io/introduction/install/}. [Accessed: 03-Apr-2019]. 

[10] ``A Universally Unique IDentifier (UUID) URN Namespace,''
\textit{IETF Tools}. [Online]. Available:
\url{https://tools.ietf.org/html/rfc4122.html}. [Accessed:
03-Apr-2019].

[11] C. H. Romie, ``Secure Hash Standard (SHS)'' Aug-2015. [Online]. Available: \url{https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf}. [Accessed: 02-Apr-2019].

[12] ``time,'' \textit{time(1) - OpenBSD manual pages}. [Online]. Available: https://man.openbsd.org/time. [Accessed: 03-Apr-2019].

[13] J. J. Vossen and A. Wanjiru, ``Discussions of Content Distribution in Kenya,'' 13-Feb-2019. 

\end{document}

%[1] https://docs.python.org/3.7/library/multiprocessing.html
%[2] https://www.pcbenchmarks.net/number-of-cpu-cores.html
%[3] https://www.raspberrypi.org/products/raspberry-pi-3-model-b/
%[4] https://www.gnu.org/software/wget/manual/wget.html
%[5] https://github.com/MarioVilas/googlesearch
%[6] https://github.com/ytdl-org/youtube-dl/
%[7] https://ipfs.io/
%[8] https://web.cs.wpi.edu/~cs513/s07/week1-unixsock.pdf
%[9] https://docs.ipfs.io/introduction/install/
%[10] https://tools.ietf.org/html/rfc4122.html
%[11] https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf
%[12] https://developer.apple.com/download/more/
%[13] Interview with Anthony.
